defaults:
  - _self_
  - env: robomimic_can
  - encoder: dino 
  - action_encoder: proprio
  - proprio_encoder: proprio
  - decoder: vqvae
  - predictor: vit
  - override hydra/launcher: submitit_slurm

# Override encoder to enable DINO reconstruction loss
encoder:
  _target_: models.dino.DinoV2Encoder
  name: "dinov2_vits14"
  feature_key: "x_norm_patchtokens"
  projected_dim: 128
  recon_dino_loss: true

# base path to save model outputs. Checkpoints will be saved to ${ckpt_base_path}/outputs.
ckpt_base_path: /mnt/data1/minghao/robomimic/checkpoints/outputs/robomimic_can_align_recon # put absolute path here

hydra:
  run:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    nodes: 1
    tasks_per_node: 2  # 使用2个GPU
    cpus_per_task: 8
    mem_gb: 256
    gres: "gpu:a100:2"  # 使用2个A100 GPU
    timeout_min: 2880
    setup: ["export DEBUGVAR=$(scontrol show hostnames $SLURM_JOB_NODELIST)",
            export MASTER_ADDR="$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
            "export MASTER_PORT=$(for port in $(shuf -i 30000-65500 -n 20); do if [[ $(netstat -tupln 2>&1 | grep $port | wc -l) -eq 0 ]] ; then echo $port; break; fi; done;)",]

training:
  seed: 0
  epochs: 100
  batch_size: 64 # Reduced to avoid memory issues
  save_every_x_epoch: 1
  reconstruct_every_x_batch: 500
  num_reconstruct_samples: 2
  encoder_lr: 1e-6
  decoder_lr: 3e-4
  predictor_lr: 5e-4
  action_encoder_lr: 5e-4

img_size: 224 # should be a multiple of 224
frameskip: 5
concat_dim: 1

normalize_action: True

# action encoder - 适配 robomimic 的 7D 动作空间
action_emb_dim: 16  # 增加维度以处理更复杂的动作空间
num_action_repeat: 1

# proprio encoder - 适配 robomimic 的 23D 状态空间
proprio_emb_dim: 32  # 增加维度以处理更复杂的状态空间
num_proprio_repeat: 1

num_hist: 3
num_pred: 1 # only supports 1
has_predictor: True # set this to False for only training a decoder
has_decoder: True # set this to False for only training a predictor

model:
  _target_: models.visual_world_model.VWorldModel
  image_size: ${img_size}
  num_hist: ${num_hist}
  num_pred: ${num_pred}
  train_encoder: False
  train_predictor: True
  train_decoder: True

# Alignment settings
alignment:
  state_consistency_loss_weight: 1.0
  alignment_regularization: 1e-4

# DINO reconstruction enabled
dino_reconstruction:
  enabled: true
  loss_weight: 1.0

debug: False 

# Planning params for planning eval jobs launched during training
plan_settings: 
  # plan_cfg_path: conf/plan.yaml # set to null for no planning evals
  plan_cfg_path: null 
  planner: ['gd', 'cem']
  goal_source: ['dset', 'random_state']
  goal_H: [5]
  alpha: [0.1, 1] 